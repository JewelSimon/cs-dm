
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>10. Predicate Logic and Proofs &#8212; Discrete Mathematics for Software Professionals 1 documentation</title>
    <link rel="stylesheet" href="_static/classic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/sidebar.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
  </head>
  <body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="nav-item nav-item-0"><a href="index.html">Discrete Mathematics for Software Professionals 1 documentation</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="predicate-logic-and-proofs">
<h1>10. Predicate Logic and Proofs<a class="headerlink" href="#predicate-logic-and-proofs" title="Permalink to this headline">¶</a></h1>
<p>In this chapter we move from propositional to a predicate logic, in
which: the values of variables range not only over :math:{matbb B}`
but over arbitrary sets; relations/predicates, such as equality, can
be used in propositions; objects can be referred to by functions that
are applied to other objects; and universal and existential operators
are supported.</p>
<p>To this point in the course, we’ve seen how to use what we call
first-order predicate logic to write specifications in Dafny. Dafny
then tries to prove such propositions for us. When we write pre- and
post-conditions, the effect that we’ve written a proposition asserting
that, “if all of the preconditions for a method are satisfied, then
the method will always terminate, and the results will satisfy the
given postconditions.”</p>
<p>We’ve thus been able to write specifications to formalize concepts
such as the surjective property of a relation, R: for every element,
y, in the co-domain of R, there exists an x in the domain of R such
that (x,y) is in R.  In Dafny notation, this is written as: forall x,
y :: y in codom() ==&gt; exists x :: x in dom() &amp;&amp; (x, y) in R. In more
ordinary mathematical notation, it’d be written as ∀ y ∈ codom(R), ∃ x
in dom(R) | (x,y) ∈ R. At this point in this course, you should be
familiar enough with these equivalent notations that you could take
English language sentences and translate them to (formalize them in)
either of these notations.</p>
<p>So you’ve seen first-order predicate logic.  We’ve also not only
studied and used but also implemented a syntax and semantics for
<em>propositional</em> logic, a much simpler logic, both syntactically and
semantically.</p>
<p>Our prop type had as its values expressions representing propositions
in propositional logic. Interpretations assigned Boolean truth values
to the variables in such expressions. The semantics of expressions
were then defined by an evaluation function that, for any expression
and interpretation, gives a truth value for the expression under that
interpretation.</p>
<p>With all that in hand, we were then able to write code to evaluate any
proposition in propositional logic under all possible interpreations,
and thus to write procedures to determine whether a given proposition
in propositional logic is valid (always true), satisfiable (true under
some interpretations), or unsatisfiable (always false).</p>
<p>Finally, with that capability finally in hand, we were able to build a
simple way to represent inference rules, then use our validity checker
to confirm that they are semantically valid rules for reasoning.</p>
<p>Having seen the syntax and semantics of propositional logic, we are
now in a much better position to discuss the syntax and semantics of
first-order predicate logic, the logical language of Dafny and also of
everyday mathematics and most of the rest of computer science. That,
in turn, will line us up for a brief introduction to the higher-order
logic of Lean and of the broader family of constructive logic proof
assistants, such as Coq.</p>
<div class="section" id="from-propositional-to-predicate-logic">
<h2>From Propositional to Predicate Logic<a class="headerlink" href="#from-propositional-to-predicate-logic" title="Permalink to this headline">¶</a></h2>
<p>Propositional logic is a very simple logic.  Expressions can contain
variables, and in some formulations, literal truth values. A key point
is that the values of a variable in propositional logic range over the
set, {true, false}, and an interpretation simply binds each variable
to one of these values.  The truth value of a large proposition is
then evaluated just as if it were a Boolean expression.</p>
<div class="section" id="variables-range-over-the-elements-of-sets">
<h3>Variables Range over the Elements of Sets<a class="headerlink" href="#variables-range-over-the-elements-of-sets" title="Permalink to this headline">¶</a></h3>
<p>First-order predicate logic is a much more expressive logic. First,
the variables in an expression in predicate logic can range over
<em>arbitrary sets</em>. Consider our definition of the surjective property
of relations. The variables, x and y, range over the domain and
codomain sets of the relation, and are not simply true and false
values.</p>
</div>
<div class="section" id="expressions-can-use-relations-predicates">
<h3>Expressions Can Use Relations/Predicates<a class="headerlink" href="#expressions-can-use-relations-predicates" title="Permalink to this headline">¶</a></h3>
<p>Second, we can use <em>relations</em> in expressions in predicate
logic. Equality and less-than are examples of relations. In predicate
logic we can thus write propositions like, p = q → r &lt; t.  This says
if p equal q then r is less than t.  This proposition makes use of
both the equals and the less than relation on whatever sets p and q
range over.</p>
<p>Such relations can be viewed as predicates, which is where the name,
“predicate logic”, comes from. For example, equality is really a
predicate on pairs, (x, y): true if and only if x and y are considered
to be equal.  Remember, a predicate is a proposition with
parameters. You give the parameters, you get back a proposition that
might or might not be true. E.g., if you give the arguments, 3 and 4,
to the = predicate, which takes two arguments, what you get back is
the proposition, 3 = 4, which of course has no proof in ordinary
mathematics. Indeed there is a proof of ¬(3 = 4).</p>
</div>
<div class="section" id="expressions-can-use-functions-to-name-values">
<h3>Expressions Can Use Functions to Name Values<a class="headerlink" href="#expressions-can-use-functions-to-name-values" title="Permalink to this headline">¶</a></h3>
<p>Third, we can use functions in predicate logic to refer to values
indirectly. We can use the number, 9, in a proposition, but we could
also write sqr(3) as an indirect way to refer to 9. Similarly in a
domain in which we’re talking about family histories, we could use a
function fatherOf(c) to refer to the father of whatever person c
refers to.</p>
</div>
<div class="section" id="predicate-logic-has-and-quantifiers">
<h3>Predicate Logic Has ∀ and ∃ Quantifiers<a class="headerlink" href="#predicate-logic-has-and-quantifiers" title="Permalink to this headline">¶</a></h3>
<p>Finally, predicate logic supports two quantifiers: forall (∀) and
exists (∃).  These quantifiers give use high expressive power. For
example, we can say in just a few symbols what it means for any
function to be surjective. Without quantifiers, we would be left to
enumerate all individual cases, which is infeasible when there are a
lot of cases, and impossible when there is an infinity of cases.</p>
</div>
</div>
<div class="section" id="from-semantic-to-syntactic-entailment">
<h2>From Semantic to Syntactic Entailment<a class="headerlink" href="#from-semantic-to-syntactic-entailment" title="Permalink to this headline">¶</a></h2>
<p>Natural deduction, which is the proof system that we’re using here, is
a set of functions (inference rules) for taking apart (elimination)
and putting together (introduction) given proofs to build new proofs.</p>
<p>Natural deduction was invented long before software tools existed, and
is one of the most basic systems for logically precise reasoning. The
Lean Prover and other similar “proof assistants” are tools that help
to automate the handling of natural deduction proof terms. Lean and
related tools use a mathematically rigorous and trusted mechanisms for
type strong, static type checking to check that proofs are valid. They
have to typecheck as values of the proposition/types they’re intended
to prove. They type checker prevents passing of arguments of the wrong
types through inference rules.  At the end of the day, you don’t have
a proof of a proposition unless the type checkers accepts it.</p>
<p>You’re learning the natural deduction style of producing proofs of
mathematical conjectures. Unlike the students doing this with paper
and pencil, you have the benefit of formal precision and automation
based on the use of a foundational type checker.</p>
<p>The cost is that now you can’t be sloppy. You have to precise about
every step and detail. Experienced mathematicians like to skip many
steps in writing proofs, when they (think they) know that the details
will all work out.</p>
<p>The upsides are that it’s much less tedious to write proofs that most
mathematicians should be able to read. The downside is that errors in
proofs leading to incorrect assumptions about the validity of critical
propositions can go undetected, leading to decisions that produce bad
outcomes. Many errors in proofs of important theorems have only been
found years after the proofs were reviewed by experts and accepted as
true in the community. When lives depend on the correctness of proofs,
it can be worth the trouble to make sure they’re right.</p>
<hr class="docutils" />
<div class="section" id="id1">
<h3>1<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>Rewrite/Delete this paragraph.  The final insight that led to a major
turn in our thinking was that, with such rules in hand, we no longer
need to resort to exhaustive checking of validity using the method of
truth tables (which doesn’t scale well at all). In place of the
concept of “semantic entailment”, we thus adopt the notion of
“syntactic entailment”, which allows us to demonstrate the truth of a
given proposition by showing that we can chain together inference
rules leading from truths determined without premises (such as that
0=0) through intermediate conclusions, to the final conclusion we want
to prove.</p>
</div>
<div class="section" id="id2">
<h3>2<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>Note to self: The next few chapters separate complexities on the way
to full first-order logic. The first, addressed here, is the shift
from a semantic to a syntactic approach to judging truth. Derivation
vs. Evaluation.</p>
<p>We will use the reasoning principles just validated semantically to
formulate analogous syntactic rules: i.e., natural deduction. These
rules provide a needed alternative to truth tables for ascertaining
truth in propositional logic. Truth tables grow too large too fast.</p>
<p>The next two chapters introduce, respectively, predicate logic without
quantifiers but including interpretations over arbitrary sets; and then
the introduction of quantifiers.
[FIX BELOW: UNDER CONSTRUCTION.]</p>
<p>One way to define a set of <em>inference</em> rules that define ways that one
can transform one set of expressions (premises) into another (a
conclusion) in such a manner that whenver all the premises are true,
the conclusion will be, too.</p>
<p>Why would anyone care about rules for transforming expressions in
abstract languages? Well, it turns out that <em>syntactic</em> reasoning is
pretty useful. The idea is that we represent a real-world phenomenon
symbolically, in such a language, so the abstract sentence means
something in the real world.</p>
<p>Now comes the key idea: if we imbue mathematical expressions with
real-world meanings and then transform these expression in accordance
with valid rules for acceptable transformations of such expressions,
then the resulting expressions will also be meaningful.</p>
<p>A logic, then, is basically a formal language, one that defines a set
of well formed expressions, and that provides a set of <em>inference</em>
rules for taking a set of expressions as premises and deriving another
one as a consequence. Mathematical logic allows us to replace human
mental reasoning with the mechanical <em>transformation of symbolic
expressions</em>.</p>
</div>
<div class="section" id="id3">
<h3>3<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>At this point, we’ve proposed and validated (using truth tables) a set
of fundamental inference rules. Unfortunately, using truth tables
doesn’t scale well. We thus play an important game, now, where we
simply accept the inference rules as valid transformation between sets
of premises and conclusions. We view the Ps, Qs, Rs in the rules we
validated as “standing for” arbitrary propositions, and we now apply
the rules without having to go back and validate the results
“semantically” (using truth tables). We thus transition from what we
call “semantic entailment” to “syntactic entailment,” which finally
moves us into the realm of symbolic logic and proof.</p>
<p>We now also shift tools, from Dafny, which allows us to write logic,
but which largely hides the proofs and their construction, to Lean,
which is what we call a proof assistant.  Many propositions are too
difficult for tools such as Dafny to prove automatically. If we still
want the assurances of correctness (of software or even just of pure
mathematics) provided by a strongly typed checker, then we have to use
a tool in which we manipulate both propositions and proofs
explicitly. We are now there.</p>
<p>The purpose of this initial unit is to give you an introduction to the
fundamental concepts of propositions and proofs when using a proof
assistant tool, here the Lean Prover. The key point of this chapter is
that different forms of propositions require the use of different
proof strategies and have different forms of proofs. These are ideas
that are fundmental to discrete mathematical whether or not you are
using a proof assistant tool such as Lean. The benefits of using Lean
include nearly absolute assurance that you haven’t made mistakes: that
proofs don’t contain errors. This technology is now also at the
forefront of important research not only in ultra high assurance
software and systems, but even in pure mathematics. Wecome to the
cutting edge!</p>
</div>
</div>
<div class="section" id="propositions-as-types">
<h2>Propositions as Types<a class="headerlink" href="#propositions-as-types" title="Permalink to this headline">¶</a></h2>
<div class="section" id="values-and-types-in-lean">
<h3>Values and Types in Lean<a class="headerlink" href="#values-and-types-in-lean" title="Permalink to this headline">¶</a></h3>
<p>Here’s a typical definition, in this case, of a variable, x, bound to
the value, 1. Both 1 and, now, x, are of type, nat.</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="n">def</span> <span class="n">x</span><span class="o">:</span> <span class="n">nat</span> <span class="o">:=</span> <span class="mi">1</span>
</pre></div>
</div>
<p>In Lean, you can check the type of a term by using the #check
command. Hover your mouse over the #check in VS Code to see the result.</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="bp">#</span><span class="kn">check</span> <span class="mi">1</span>
<span class="bp">#</span><span class="kn">check</span> <span class="n">x</span>
</pre></div>
</div>
<p>Lean tells you that the type of x is nat.  It uses the standard
mathematical script N (ℕ) for nat. You can use it too by typing “\nat”
rather than just “nat” for the type.</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="n">def</span> <span class="n">x&#39;</span><span class="o">:</span> <span class="bp">ℕ</span> <span class="o">:=</span> <span class="mi">1</span>
</pre></div>
</div>
<p>You can evaluate an expression in Lean using the #eval command. (There
are other ways to do this, as well, which we’ll see later.) You hover
your mouse over the command to see the result.</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="bp">#</span><span class="kn">eval</span> <span class="n">x</span>
</pre></div>
</div>
<p>In Lean, definitions start with the keyword, def, followed by the name
of a variable, here x; a colon; then the declared type of the
variable, here nat; then :=; and finally an expression of the right
type, here simply the literal expression, 1, of type ℕ. Lean
type-checks the assignment and gives and error if the term on the
right doesn’t have the same type declared or inferror for the variable
on the left.</p>
<p>In Lean, every term has a type. A type is a term, too, so it, too, has
a type. We’ve seen that the type of x is nat. What is the type of nat?</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="bp">#</span><span class="kn">check</span> <span class="n">nat</span>
</pre></div>
</div>
<p>What is the type of Type?</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="bp">#</span><span class="kn">check</span> <span class="kt">Type</span>
</pre></div>
</div>
<p>What is the type of Type 1?</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="bp">#</span><span class="kn">check</span> <span class="kt">Type</span> <span class="mi">1</span>
</pre></div>
</div>
<p>You can guess where it goes from here!</p>
</div>
<div class="section" id="propositions">
<h3>Propositions<a class="headerlink" href="#propositions" title="Permalink to this headline">¶</a></h3>
<p>Lean and similar constructive logic proof assistants unify and
automate mathematical logic and computing. So propositions are now
values, and so are proofs. As such, propositions must have
types. Let’s write a few simple propositions and check to see what
their types are.</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="c1">-- zero equals zero; this is a proposition</span>
<span class="bp">#</span><span class="kn">check</span> <span class="mi">0</span><span class="bp">=</span><span class="mi">0</span>
</pre></div>
</div>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="c1">-- every natural numbers is non-negative</span>
<span class="bp">#</span><span class="kn">check</span> <span class="bp">∀</span> <span class="n">n</span><span class="o">:</span> <span class="n">nat</span><span class="o">,</span> <span class="n">n</span> <span class="bp">&gt;=</span> <span class="mi">0</span>
</pre></div>
</div>
<p>Get the forall symbol by typing “\forall”</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="c1">-- every natural number has a successor</span>
<span class="bp">#</span><span class="kn">check</span> <span class="bp">∀</span> <span class="n">n</span><span class="o">:</span> <span class="bp">ℕ</span><span class="o">,</span> <span class="bp">∃</span> <span class="n">m</span><span class="o">:</span> <span class="bp">ℕ</span><span class="o">,</span> <span class="n">m</span> <span class="bp">=</span> <span class="n">n</span> <span class="bp">+</span> <span class="mi">1</span>
</pre></div>
</div>
<p>Get the exists symbol by typing “\exists”</p>
<p>In each case, we see that the type of a
proposition is Prop. What’s the type of Prop?</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="bp">#</span><span class="kn">check</span> <span class="kt">Prop</span>
</pre></div>
</div>
<p>Ok, the type of Prop is also Type. So what we have here is a type
hierarchy in which the familiar types, such as nat, have the type,
Type, but where there’s also a type, called Prop, that is also of
type, Type, and that, in turn, is the type of all propositions.</p>
<p>So let’s start again with x := 1. The value of x is 1. The type of the
value, 1, is nat.  The type of nat is Type. From there the type of
each type is just the next bigger “Type n.”“</p>
<p>We’ve also seen that a proposition, such as 0=0, is of type, Prop,
which in turn has the type, Type. But what about proofs?  -/</p>
</div>
</div>
<div class="section" id="proofs-as-values-of-propositional-types">
<h2>Proofs as Values of Propositional Types<a class="headerlink" href="#proofs-as-values-of-propositional-types" title="Permalink to this headline">¶</a></h2>
<p>So what about proofs? They crazy idea that Lean and similar systems
are built on is that propositions can themselves be viewed as types,
and proofs as values of these types! In this analogy, a proof is a
value of a type, namely of the proposition that it proves, viewed as a
type. So just as 1 is a value of type nat, and nat in turn is a value
of type, Type, so a proof of 0=0 is a value of type 0=0! The
proposition is the type, the proof, if there is one, is a value of
such a type. The type of a proposition (itself a type) is Prop.  And
the type of Prop is Type. To see this clearly, we need to build some
proof values.</p>
<p>Here (following this comment) is another definition, of the variable,
zeqz. But whereas before we defined x to be of the type, nat, now we
define zeqz to be of the type, 0=0. We’re using a proposition as a
type! To this variable we then assign a value, which we will
understand to be a proof. Proof values are built by what we can view
as inference rules. The inference rule, rfl, build a proof that
anything is equal to itself</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="n">def</span> <span class="n">zeqz</span><span class="o">:</span> <span class="mi">0</span> <span class="bp">=</span> <span class="mi">0</span> <span class="o">:=</span> <span class="n">rfl</span>
</pre></div>
</div>
<p>The proof is produced the rfl inference rule.  The rfl “proof
constructor” (that is what an inference rule is, after all) is
polymorphic, uses type inference, takes a single argument, a, and
yields a proof of a = a. The value in this case is 0 and the type is
nat. What the rule rule says more formally is that, without any
premises you can conclude that for any type, A, and for any value, a,
of that type, there is a proof of a = a. For example, if you need a
proof of 0=0, you use this rule to build it. The rule infers the type
to be nat and the value, a, to be 0. The result is a proof of the
proposition 0 = 0. The value of zeqz is thus a <em>proof</em>, a proof of its
type, i.e., of the logical proposition, 0 = 0. Checke the type of
zeqz. Its type is the proposition that it is a proof of!</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="bp">#</span><span class="kn">check</span> <span class="n">zeqz</span>
</pre></div>
</div>
<p>It helps to draw a picture. Draw a picture that includes “nodes” for
all of the values we’ve used or defined so far, with arrows depicting
the “hasType” relation. There are nodes for 1, x, zeqz, nat, Prop,
Type, Type 1, Type 2, etc.</p>
<p>When we’re building values that are proofs of propositions, we
generally use the keyword, “theorem”, instead of “def”. They mean
exactly the same thing to Lean, but they communicate different
intentions to human readers. We add a tick mark to the name of the
theorem here only to avoid giving multiple definitions of the same
name, which is an error in Lean.</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="kn">theorem</span> <span class="n">zeqz&#39;</span><span class="o">:</span> <span class="mi">0</span> <span class="bp">=</span> <span class="mi">0</span> <span class="o">:=</span> <span class="n">rfl</span>
</pre></div>
</div>
<p>We could have defined x := 1 as a theorem.</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="kn">theorem</span> <span class="n">x&#39;&#39;</span><span class="o">:</span> <span class="n">nat</span> <span class="o">:=</span> <span class="mi">1</span>
</pre></div>
</div>
<p>While this means exactly the same thing as our original definition of
x, it gives us an entirely new view: a value is a proof of its type. 1
is thus a proof of the type nat. Our ability to provide any value for
a type gives us a proof of that type. The type checker in Lean of
course ensures that we never assign a value to a variable that is not
of its declared or inferred type.</p>
<p>What does it mean, then, for a proposition to be true in Lean? It
means exactly that there is some value of that type. A proposition
that is false is a good proposition, and a good type, but it is a type
that has no values! It’s an “empty” type. The type, 1=0, has no values
(no proofs).  To prove a proposition (a type) in Lean means that one
has produced/exhibited a value of that type: a value that the type
checker confirms is of that type.</p>
<p>With this background in hand, we can now use what we’ve learned to
start to investigate the world of mathematical logic and proof at a
very high level of sophistication and automation!</p>
<p>In particular, we now explore different <em>forms of propositions</em> and
corresponding <em>proof strategies</em>. Learning to recognize what kind of
proposition you’re looking at and to pick the right proof strategy for
that kind of proposition is really important. In this unit, we look at
strategies for proving propositions that assert equalities, and
propositions involving conjunctions, disjunctions, and implications.</p>
</div>
<div class="section" id="proving-propositions-involving-equalities">
<h2>Proving Propositions Involving Equalities<a class="headerlink" href="#proving-propositions-involving-equalities" title="Permalink to this headline">¶</a></h2>
<p>We start with propositions that assert equalities. An expression,
v1=v2, is a proposition that asserts the equality of the terms v1 and
v2.  There is an inference rule defined in Lean (in its libraries),
called <em>rfl</em>, that produces a proof of such a proposition whenever v1
and v2 are exactly the same term, as in 0=0. The <em>rfl</em> inference rule
(we might also now call it a proof constructor) also produces a proof
whever v1 and v2 evaluate to identical terms, as in 0+0=0. 0+0 reduces
to 0; 0 is already fully reduced; and with identical reduced terms on
each side of the =, the proof can be constructed. The <em>rfl</em> inference
rule is polymorphic, and therefore can be used to assert the equality
of any two terms of the same type, A, no matter what A is.</p>
<p>Here are several terms that are considered equal even though they’re
not identical. rfl is happy to build proofs for them.</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="kn">theorem</span> <span class="n">t0</span> <span class="o">:</span> <span class="mi">1</span> <span class="bp">-</span> <span class="mi">1</span> <span class="bp">=</span> <span class="mi">5</span> <span class="bp">-</span> <span class="mi">5</span> <span class="o">:=</span> <span class="n">rfl</span>
<span class="kn">theorem</span> <span class="n">t1</span> <span class="o">:</span> <span class="o">(</span><span class="mi">1</span><span class="bp">-</span><span class="mi">1</span><span class="o">,</span> <span class="s2">&quot;fidgblof&quot;</span><span class="o">)</span><span class="bp">.</span><span class="mi">1</span> <span class="bp">=</span> <span class="mi">0</span> <span class="o">:=</span> <span class="n">rfl</span>
</pre></div>
</div>
<p>The second example illustrates that terms that look pretty different
can still be definitionally equal. On the left we have a nat/string
pair. The .1 after the pair is the operator that extracts the first
element of the pair, here term 1-1. This term then reduces to 0. The
terms on either side of the = reduce to the same term, 0, which allows
rfl to complete its work and return a value that is accepted as being
of the right type, i.e., as a proof of equality.</p>
<p>What you are seeing here is a strategy of proving propositions that
assert equalities in two steps: first simplify (evaluate) the
expressions on either side of the =, and then certify a proof of
equality if and only if the resulting terms are identical.  Whether
you are using a proof assistant tool such as Lean or just doing
paper-and-pencil mathematics, this is a fundamental strategy for
proving propositions of a certain kind, namely propositions that
assert equalities.</p>
</div>
<div class="section" id="true-introduction">
<h2>True Introduction<a class="headerlink" href="#true-introduction" title="Permalink to this headline">¶</a></h2>
<p>Recall from our introduction to inference rules in propositional logic
that the proposition, pTrue, is true without any preconditions. We
wrote the rule like this: ([],pTrue), and we called it “true intro”.
We proved the rule semantically valid, so we can write [] <a href="#id4"><span class="problematic" id="id5">|</span></a>=
pTrue. That is, from an empty context (no previous assumptions) we can
conclude that pTrue is true.</p>
<p>In lean, “true” is the true proposition.  You can check that “true” is
a proposition using #check.</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="bp">#</span><span class="kn">check</span> <span class="n">true</span>
</pre></div>
</div>
<p>Note: the proposition, true, is different than the Boolean value,
true. The Boolean value, true is written “tt” in Lean. It is one of
the two values of the bool datatype. It is not a proposition.  Chek it
out.</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="bp">#</span><span class="kn">check</span> <span class="n">tt</span>
</pre></div>
</div>
<p>In Lean and similar proof assistants, propositions, such as true in
Lean, can be defined inductively. The keyword for an inductive
datatype in Dafny is just “datatype”. Recall the definition of our
syntax for propositional logic, for example. The values of a type are
defined by a list of contructors.</p>
<p>As proofs are values of types, we can define propositions as types and
proofs of such propositions as values produced by constructors. The
simplest example is the proposition, true, in Lean. It’s defined in
Lean’s core library like so:</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="kn">inductive</span> <span class="n">true</span> <span class="o">:</span> <span class="kt">Prop</span>
<span class="bp">|</span> <span class="n">intro</span> <span class="o">:</span> <span class="n">true</span>
</pre></div>
</div>
<p>This says that true is of type Prop, i.e., is a proposition, and it
has just one value, proof, namely “intro”. The constructor says,
“intro” is of type (i.e., is a proof of) true. The intro constructor
takes no arguments and so is always available as a proof of true.  We
thus have our true introduction: just use the constructor. Here we
should how to assert that the proposition “true” is true (there’s a
proof for it) by giving the one and only proof, namely “intro”.  To
refer to a constructor of a type, use the type name dot constructor
name.</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="kn">theorem</span> <span class="n">trueIsProvable</span><span class="o">:</span> <span class="n">true</span> <span class="o">:=</span> <span class="n">true</span><span class="bp">.</span><span class="n">intro</span>
</pre></div>
</div>
<p>This isn’t a very useful rule of natural
deduction, as it doesn’t really tell you
anything you didn’t already know. It is not
commonly used in proofs.</p>
</div>
<div class="section" id="the-proposition-false">
<h2>The Proposition, false<a class="headerlink" href="#the-proposition-false" title="Permalink to this headline">¶</a></h2>
<p>In Lean, false is a proposition. The Boolean false value is written as
ff.)  Check it out in Lean.</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="bp">#</span><span class="kn">check</span> <span class="n">false</span>
</pre></div>
</div>
<p>The false proposition is defined so as never to be true, i.e., not
provable.  It’s defined inductively as a propositional type having
exactly no constructors! It’s a proposition but there is absolutely no
way to contruct a proof of it. Here’s how it’s written.</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="kn">inductive</span> <span class="n">false</span> <span class="o">:</span> <span class="kt">Prop</span>
</pre></div>
</div>
<p>That’s it. Look, no constructors!  There can be no false introduction
rule because there is no way to introduce a proof of false. You can
never complete a definition such as this one:</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="kn">theorem</span> <span class="n">impossible</span><span class="o">:</span> <span class="n">false</span> <span class="o">:=</span> <span class="bp">&lt;</span><span class="n">nothing</span> <span class="n">works</span> <span class="n">here</span><span class="bp">&gt;</span>
</pre></div>
</div>
<p>We’ll discuss the rule for false elimination later in this chapter.</p>
</div>
<div class="section" id="proving-propositions-involving-conjunctions">
<h2>Proving Propositions Involving Conjunctions<a class="headerlink" href="#proving-propositions-involving-conjunctions" title="Permalink to this headline">¶</a></h2>
<p>We now look at how to produce proofs of propositions involving
conjunctions: propositions of the form, P ∧ Q.</p>
<p>In some cases, we will have obtained proofs of P and Q, we want a
proof of P ∧ Q. The <em>and introduction</em> natural deduction inference
rule is the key. When applied to proofs, pfP and pfQ, of propositions
P and Q, it constructs and returns a proof of the proposition P ∧ Q.
Such a proof the ordered pair, (pfP, pfQ), of the proofs of P and Q,
labelled with a constructor name indicates that it represents a proof
of P ∧ Q.</p>
<p>In the other cases, we will have obtained a proof of P ∧ Q and we
will want a proof of P or a proof of Q. The <em>and elimination</em> rules
effects these transformation between propositions.</p>
<div class="section" id="p-q-p-q-and-introduction">
<h3><a href="#id6"><span class="problematic" id="id7">*</span></a>[P, Q] <a href="#id8"><span class="problematic" id="id9">|</span></a>- P /Q (And Introduction)<a class="headerlink" href="#p-q-p-q-and-introduction" title="Permalink to this headline">¶</a></h3>
<p>The key idea is simple: a proof of P ∧ Q can be constructed if and
only if you have (or can produce) both a proof of P and a proof
of Q. In that case, you can use the and introduction rule to build the
desired proof. Remember the rule: [P, Q] ⊢ P ∧ Q.  Now we can write
this rule to distinguish propositions, such a P and Q, from proofs.
[pfP: P, pfQ: Q] ⊢ (pfP, pfQ): P ∧ Q. In other words, if I have a
proof, pfP, of P (a value, pfP, type, P!), and a proof, pfQ, of Q,
then I can build a proof, (pfP, pfQ), of P ∧ Q; and the proof of the
conjuction is just the ordered pair of the individual proof values!
The and introduction rule can be understood as a function that takes
two proof values and returns them as an ordered pair, which in Lean
proves the conjunction of the corresponding propositions.</p>
<p>Whether using a proof assistant or just doing paper and pencil math,
the strategy for proving a conjunction of propositions is to split the
conjunction into its two component propositions, obtain proofs of them
individually, and then combine/take the two proofs as a proof of the
overall conjunction. The benefit of using a proof assistant is that
aspects are automated, and you’re not allowed to make mistakes.</p>
<p>So that we can play around with this idea, given that we already have
a proof of 0=0 (zeqz), we now contruct a proof of 1=1 so that we have
two propositions and proofs to play with.</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="kn">theorem</span> <span class="n">oeqo</span> <span class="o">:</span> <span class="mi">1</span> <span class="bp">=</span> <span class="mi">1</span> <span class="o">:=</span> <span class="n">rfl</span>
</pre></div>
</div>
<p>To start, we conjecture that 0=0 /1=1. We already have a proof of
0=0, namely zeqz.  And we already have a proof of 1=1, namely oeqo. So
we should be able to produce a proof of 0=0 /1=1 by using the “and
introduction” inference rule. Remember that it says that if a
proposition, P, is true (and now by that we mean that we have a proof
of it), and if Q is true, then we can deduce (construct a proof!)
that P ∧ Q is true. Here’s how you do that in Lean. (Note: we get the
logical and symbol, ∧, by typing “and”, i.e., backslash-and, followed
by a space.)</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="kn">theorem</span> <span class="n">t2</span><span class="o">:</span> <span class="mi">0</span><span class="bp">=</span><span class="mi">0</span> <span class="bp">∧</span> <span class="mi">1</span><span class="bp">=</span><span class="mi">1</span> <span class="o">:=</span>  <span class="c1">-- proposition</span>
    <span class="n">and</span><span class="bp">.</span><span class="n">intro</span> <span class="n">zeqz</span> <span class="n">oeqo</span>   <span class="c1">-- build proof</span>
</pre></div>
</div>
<p>Whereas we typically define functions to take a single tuples of
argument values, and thus write the arguments to functions as tuples
(in parenthesis), e.g., inc(0), in Lean we write the arguments to
proof constructors (inference rules) without parenthesis and without
commas between values. (The difference is in currying, which we will
discuss at another time.)</p>
<p>So here for example, and below, we write “and.intro zeqz oeqo” rather
than “and.intro(zeqz, oeqo)”. Be careful when you get to the exercises
to remember this point.</p>
<p>The preceding code should make it clear that and.intro is, for all
intents and purposes, a function that takes proofs of 0=0 and 1=1,
respectively, and constructs a proof of 0=0 /1=1. As we’ve already
discussed, such a proof is in essence the ordered pair of the given
proof values.</p>
</div>
<div class="section" id="p-q-p-p-q-q-and-elimination-rules-left-and-right">
<h3>[P /Q] <a href="#id10"><span class="problematic" id="id11">|</span></a>- P, [P /Q] <a href="#id12"><span class="problematic" id="id13">|</span></a>- Q. [And Elimination rules (left and right)]<a class="headerlink" href="#p-q-p-p-q-q-and-elimination-rules-left-and-right" title="Permalink to this headline">¶</a></h3>
<p>As such, we should be able to extract the individual proofs from such
a pair, and that is what the and elimination rules do!  There are two,
one to obtain each element.  Thus from a proof of P ∧ Q we can apply
the and elimination rules to obtain a proof of P and a proof of Q.</p>
</div>
</div>
<div class="section" id="interlude-function-types-values-expressions">
<h2>Interlude: Function Types, Values, Expressions<a class="headerlink" href="#interlude-function-types-values-expressions" title="Permalink to this headline">¶</a></h2>
<p>It will help to spend a little more time talking about functions and
function types. In particular, we’ll introduce here a new notation for
saying something that you already know how to say well: a way to
represent function bodies without having to give them names. These are
given the somewhat arcane name, lambda expressions, also written as λ
expressions. So let’s get started.</p>
<p>We can define functions in Lean almost as in Dafny. Here are two
functions to play with: increment and square. Go back and look at the
function.dfy file to see just how similar the syntax is.</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="n">def</span> <span class="n">inc</span><span class="o">(</span><span class="n">n</span><span class="o">:</span> <span class="n">nat</span><span class="o">):</span> <span class="n">nat</span> <span class="o">:=</span> <span class="n">n</span> <span class="bp">+</span> <span class="mi">1</span>
<span class="n">def</span> <span class="n">sqr</span><span class="o">(</span><span class="n">n</span><span class="o">:</span> <span class="n">nat</span><span class="o">):</span> <span class="n">nat</span> <span class="o">:=</span> <span class="n">n</span> <span class="bp">*</span> <span class="n">n</span>
<span class="n">def</span> <span class="n">comp</span><span class="o">(</span><span class="n">n</span><span class="o">:</span> <span class="n">nat</span><span class="o">):</span> <span class="n">nat</span> <span class="o">:=</span> <span class="n">sqr</span> <span class="o">(</span><span class="n">inc</span> <span class="n">n</span><span class="o">)</span>
</pre></div>
</div>
<p>Now’s a good time to make a point that should make sense: functions
are values of function types. Our familiar notation doesn’t make
function types explicit, but it shouldn’t be a stretch for you to
accept that the type of inc is nat → nat.  Lean provides nice
mathematical notation so if you type “\nat” you’ll get ℕ. So, that
type of inc is best written, ℕ → ℕ.</p>
<div class="section" id="anonymous-functions-lambda-expressions">
<h3>Anonymous Functions (Lambda Expressions)<a class="headerlink" href="#anonymous-functions-lambda-expressions" title="Permalink to this headline">¶</a></h3>
<p>We could thus have declared inc to be a value of type ℕ → ℕ, to which
we would then assign a function value. That is a new concept: we need
to write formally what we’d say informally as “the function that takes
a nat, n, as an argument and that returns the nat, n + 1 as a result.”</p>
<p>The way we write that in Lean (and in what we call the lambda calculus
more generally) is “λ n, n + 1”. The greek letter, lambda (λ), says
“the following variable is an argument to a function”.  Then comes a
comma followed by the body of the function, usually using the name of
the argument. Here then is the way we’d rewrite inc using this new
notation.</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="n">def</span> <span class="n">inc&#39;</span><span class="o">:</span> <span class="bp">ℕ</span> <span class="bp">→</span> <span class="bp">ℕ</span> <span class="o">:=</span> <span class="bp">λ</span> <span class="n">n</span><span class="o">:</span> <span class="n">nat</span><span class="o">,</span> <span class="n">n</span> <span class="bp">+</span> <span class="mi">1</span>
</pre></div>
</div>
<p>As you might suspect, from the function value, Lean can infer its
type, so you don’t have to write it explicitly. But you do have to
write the type of n here, as Lean can’t figure out if you mean nat or
int or some other type that supports a * operator.</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="n">def</span> <span class="n">sqr&#39;</span> <span class="o">:=</span> <span class="bp">λ</span> <span class="n">n</span><span class="o">:</span> <span class="n">nat</span><span class="o">,</span> <span class="n">n</span> <span class="bp">*</span> <span class="n">n</span>
</pre></div>
</div>
<p>Given a function defined in this way, you can apply it just as you
would apply any other function.</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="n">def</span> <span class="n">sq3</span> <span class="o">:=</span> <span class="n">sqr&#39;</span> <span class="mi">3</span>
</pre></div>
</div>
<p>Don’t believe that sq3 is therefore of type nat? You can check the
type of any term in Lean using its #check command.  Just hover your
mouse over the #check.</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="bp">#</span><span class="kn">check</span> <span class="n">sq3</span>
</pre></div>
</div>
<p>Do you want to evaluate the expression (aka, term) sq3 to see that it
evaluates to 9? Hover your mouse over the #eval.</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="bp">#</span><span class="kn">eval</span> <span class="n">sq3</span>
</pre></div>
</div>
</div>
<div class="section" id="recursive-functions">
<h3>Recursive Functions<a class="headerlink" href="#recursive-functions" title="Permalink to this headline">¶</a></h3>
<p>We can also define recursive functions, such as factorial and
fibonacci using Lean’s version of Dafny’s “match/case” construct (aka,
“pattern matching”).</p>
<p>Here’s how you write it. The first line declares the function name and
type. The following lines, each starting with a bar character, define
the cases. The first rule matches the case where the argument to fac
is 0, and in that case the result is 1. The second case, which is
written here a little differently than before, matches any value that
is one more than some smaller argument, n, and returns that “one more
than n” times the factorial of the samller number, n. Writing it this
way allows Lean to prove to itself that the recursion terminates.</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="n">def</span> <span class="n">fac</span><span class="o">:</span> <span class="bp">ℕ</span> <span class="bp">→</span> <span class="bp">ℕ</span>
             <span class="bp">|</span> <span class="mi">0</span> <span class="o">:=</span> <span class="mi">1</span>
             <span class="bp">|</span> <span class="o">(</span><span class="n">n</span> <span class="bp">+</span> <span class="mi">1</span><span class="o">)</span> <span class="o">:=</span> <span class="o">(</span><span class="n">n</span> <span class="bp">+</span> <span class="mi">1</span><span class="o">)</span> <span class="bp">*</span> <span class="n">fac</span> <span class="n">n</span>
</pre></div>
</div>
<p>We can now write some test cases for our function … as little
theorems! And we can check that they work by … proving them! Here
once again our proof is by the reflexive property of equality, and
lean is automatically reducing (simplifying) the terms (fac 5) and 120
before checking that the results are the same. fac 5 does in fact
reduce to 120, so the terms, fac 5, and 120, are definitionally equal,
and in this case, rfl constructs a proof of the equality.</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="kn">theorem</span> <span class="n">fac5is120</span> <span class="o">:</span> <span class="n">fac</span> <span class="mi">5</span> <span class="bp">=</span> <span class="mi">120</span> <span class="o">:=</span> <span class="n">rfl</span>
</pre></div>
</div>
</div>
<div class="section" id="functions-that-take-and-return-proofs">
<h3>Functions that Take and Return Proofs<a class="headerlink" href="#functions-that-take-and-return-proofs" title="Permalink to this headline">¶</a></h3>
<p>So far we’ve see how to build proofs of equality propositions (using
simplification and reflexivity, i.e., rfl), of conjunctions (using
and.intro), and of disjuctions (using one of the or introduction
rules). What about implications?</p>
<p>Suppose we wanted to show, for example, that (1=1 ∧ 0=0() → (0=0 ∧
1=1). Here the order of the conjuncts is reversed.</p>
<p>How to think about this? First, remember that an implication, such as
P → Q, doesn’t claim that the conclusion, P, is necessarily true.
Rather, it only claims that <a href="#id14"><span class="problematic" id="id15">*</span></a>if the premise is true, then the
conclusion is true. Now, by “true”, we mean that we have or can
construct a proof. An implication is thus read as saying if you assume
that the premise, P, is true, in other words if you assume you have a
proof of P, then you can then derive a proof of the conclusion, Q. But
proofs are just values of (these strange propositional) types, and so
a proposition in the form of an implication, such as P → Q is true
exactly when we have a way to convert any value (proof) of type P into
a value (proof) of type Q. We call such things, that change values
into other values, functions! Think about this: the implication, P → Q
is true if we can define a function of type, yep, you guessed it, P
→ Q. Whoa!</p>
<p>So now, think about how to write a function that takes an argument of
type 1=1 ∧ 0=0 and that returns a result of type 0=0 ∧ 1=1. To make it
even clearer, understand that a proof of a conjunction is a pair of
proofs, the and elimination rules just give you the values in such
pairs, and the and introduction rule just forms such an ordered pair
given arguments of the right types. The strategy for writing the
function we need is thus:</p>
<p>start with (proof of 1=1, proof of 0=0) as a pair proving 1=1 ∧ 0=0;
extract each of the component proofs, then construct and return a pair
constituting a proof of the conjunction with the component proofs in
the opposite order.</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="kn">theorem</span> <span class="n">and_swap</span><span class="o">:</span> <span class="mi">1</span><span class="bp">=</span><span class="mi">1</span> <span class="bp">∧</span> <span class="mi">0</span><span class="bp">=</span><span class="mi">0</span> <span class="bp">→</span> <span class="mi">0</span><span class="bp">=</span><span class="mi">0</span> <span class="bp">∧</span> <span class="mi">1</span><span class="bp">=</span><span class="mi">1</span> <span class="o">:=</span>
     <span class="bp">λ</span> <span class="n">premise</span><span class="o">:</span> <span class="mi">1</span><span class="bp">=</span><span class="mi">1</span> <span class="bp">∧</span> <span class="mi">0</span><span class="bp">=</span><span class="mi">0</span><span class="o">,</span>
         <span class="n">and</span><span class="bp">.</span><span class="n">intro</span>
             <span class="o">(</span><span class="n">and</span><span class="bp">.</span><span class="n">elim_right</span> <span class="n">premise</span><span class="o">)</span>
             <span class="o">(</span><span class="n">and</span><span class="bp">.</span><span class="n">elim_left</span> <span class="n">premise</span><span class="o">)</span>
</pre></div>
</div>
<p>If using lambda is still confusing at this point, just write it as an
ordinary function, and then give the function name as the proof.</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="n">def</span> <span class="n">and_swap_fun</span><span class="o">(</span><span class="n">premise</span><span class="o">:</span> <span class="mi">1</span><span class="bp">=</span><span class="mi">1</span> <span class="bp">∧</span> <span class="mi">0</span><span class="bp">=</span><span class="mi">0</span><span class="o">):</span> <span class="mi">0</span><span class="bp">=</span><span class="mi">0</span> <span class="bp">∧</span> <span class="mi">1</span><span class="bp">=</span><span class="mi">1</span> <span class="o">:=</span>
     <span class="n">and</span><span class="bp">.</span><span class="n">intro</span>
     <span class="o">(</span><span class="n">and</span><span class="bp">.</span><span class="n">elim_right</span> <span class="n">premise</span><span class="o">)</span>
     <span class="o">(</span><span class="n">and</span><span class="bp">.</span><span class="n">elim_left</span> <span class="n">premise</span><span class="o">)</span>

 <span class="kn">theorem</span> <span class="n">and_swap&#39;</span><span class="o">:</span> <span class="mi">1</span><span class="bp">=</span><span class="mi">1</span> <span class="bp">∧</span> <span class="mi">0</span><span class="bp">=</span><span class="mi">0</span> <span class="bp">→</span> <span class="mi">0</span><span class="bp">=</span><span class="mi">0</span> <span class="bp">∧</span> <span class="mi">1</span><span class="bp">=</span><span class="mi">1</span> <span class="o">:=</span>
     <span class="n">and_swap_fun</span> <span class="c1">-- give named function as proof</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="proving-propositions-involving-implications">
<h2>Proving Propositions Involving Implications<a class="headerlink" href="#proving-propositions-involving-implications" title="Permalink to this headline">¶</a></h2>
<p>Next we turn to proofs of propositions in the form of implications.
An example is P → Q.  Up until now, we’ve read this implication as
asserting that “if P is true then Q is true.” Now that we have taken
truth to be judged by the existence of a proof, we can view P → Q as
asserting that if a proof of P can be given, then a proof of Q can be
constructed. We begin this time with the elimination rule, and then
we introduce the introduction rule, clearing up a loose end created
when we skipped over this rule in our work on propositional logic.</p>
<div class="section" id="p-q-p-q-elimination">
<h3>P → Q, P <a href="#id16"><span class="problematic" id="id17">|</span></a>- Q  [ → elimination]<a class="headerlink" href="#p-q-p-q-elimination" title="Permalink to this headline">¶</a></h3>
<p>The rule for or elimination says that if we have a proof of P → Q
(call it pfPQ) and we have a proof of P (call it pfP), then we can
derive a proof (pfQ) of Q.  In effect, a proof of P → Q, pfPQ, as we
discuss below, is a function, of type P → Q, that, given a proof of P
(a value of type P), returns a proof of Q. If we have such a function
and a proof of P, then we can just <em>apply</em> the function to the proof
to get a proof of Q. The function application expression, <em>pfPQ P</em>,
type checks and reduces to a proof of Q. Aristotle’s <em>modus ponens</em> is
just function application, with proofs as argument and result.</p>
<p>What does the type P → Q look like?! It looks like a function type:
for a function that when given any value of type, P, returns a value
of type, Q. And indeed, that’s just what we want! We will view P → Q,
the proposition, to be true, if and only if we can produce a function
that, when given any proof of (value of type) P, gives us back a proof
of (value of type) Q. If there is such a function, it means that if P
is true (if you can produce a proof value for P) then Q is true (you
can obtain a proof of Q by applying the function to the proof of P).</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="kn">theorem</span> <span class="n">t8</span><span class="o">:</span> <span class="o">(</span><span class="n">P</span> <span class="bp">→</span> <span class="n">Q</span><span class="o">)</span> <span class="bp">-&gt;</span> <span class="n">P</span> <span class="bp">-&gt;</span> <span class="n">Q</span> <span class="o">:=</span>
     <span class="bp">λ</span> <span class="n">pf_impl</span><span class="o">:</span> <span class="o">(</span><span class="n">P</span> <span class="bp">→</span> <span class="n">Q</span><span class="o">),</span> <span class="o">(</span><span class="bp">λ</span> <span class="n">pf_P</span><span class="o">:</span> <span class="n">P</span><span class="o">,</span> <span class="n">pf_impl</span> <span class="n">pf_P</span><span class="o">)</span>
</pre></div>
</div>
</div>
<div class="section" id="p-q-p-q-introduction">
<h3>[P <a href="#id18"><span class="problematic" id="id19">|</span></a>- Q] <a href="#id20"><span class="problematic" id="id21">|</span></a>- (P → Q)  [ → introduction ]<a class="headerlink" href="#p-q-p-q-introduction" title="Permalink to this headline">¶</a></h3>
<p>The inference rule for arrow introduction says that if assuming that P
is true (in which case you assume you have a proof of P) enables you
to produce a proof of Q (i.e., if there is a derivation from P to Q),
then you can conclude (produce a proof) that P → Q. The statement of
the inference rule involves a nested inference rule, which is why we
skipped over this rule in the chapter on propositional logic.</p>
<p>There is no explicit → introduction function in Lean. Rather, you
introduce an arrow by defining a function of the desired arrow type:
e.g., from values-of-type/proofs-of P to values-of-type/proofs-of Q.</p>
<div class="highlight-dafny"><div class="highlight"><pre><span></span>theorem and_swap: 1=1 ∧ 0=0 → 0=0 ∧ 1=1 :=
     λ premise: 1=1 ∧ 0=0,
         and.intro
             (and.elim_right premise)
             (and.elim_left premise)
</pre></div>
</div>
</div>
</div>
<div class="section" id="proving-propositions-involving-disjunctions">
<h2>Proving Propositions Involving Disjunctions<a class="headerlink" href="#proving-propositions-involving-disjunctions" title="Permalink to this headline">¶</a></h2>
<p>Proofs involving disjunctions are of two kinds.  In one case we’re
given a proof of P, or a proof of Q, and we want to introduce an ∨ to
produce a proof of P ∨ Q. This is easy, as a proof of either P or Q
alone suffices to justify the contruction of a proof of P ∨ Q.</p>
<p>In the other case, we’re given a proof of P ∨ Q and we want to derive
a proof of a proposition without that ∨. In this case, the inference
rule takes not only a proof of P ∨ Q, but also proofs of two other
propositions: P → R, and Q → R.</p>
<blockquote>
<div>P <a href="#id22"><span class="problematic" id="id23">|</span></a>- P / Q;  Q <a href="#id24"><span class="problematic" id="id25">|</span></a>- P / Q  [Or Introduction]</div></blockquote>
<hr class="docutils" />
<p>To prove a conjunction, we saw that we need to construct a pair of
proofs, one for each conject. To prove a disjunction, P ∨ Q, we just
need a proof of P or a proof of Q. We thus have two inference rules to
prove P ∨ Q, one takeing a proof of P and returning a proof of P ∨ Q,
and one taking a proof of Q and returning a proof of P ∨ Q.  We thus
have two or introduction rules in the natural deduction proof system,
one taking a proof of the left disjunct (P), and one taking a proof of
the right (Q).</p>
<p>For example, we can prove the proposition, 0=0 ∨ 1=0 using an “or
introduction” rule.  In general, you have to decide which rule will
work. In this case, we won’t be able to build a proof of 1=0 (it’s not
true!), but we can build a proof of 0=0, so we’ll do that and then use
the left introduction rule to generate a proof of the overall
proposition.</p>
<p>The or introduction rules in Lean are called or.inl (left) and or.inr
(right).  Here then we construct a proof just as described above, but
now checked by the tool.</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="kn">theorem</span> <span class="n">t3</span><span class="o">:</span> <span class="mi">0</span><span class="bp">=</span><span class="mi">0</span> <span class="bp">∨</span> <span class="mi">1</span><span class="bp">=</span><span class="mi">0</span> <span class="o">:=</span>
             <span class="n">or</span><span class="bp">.</span><span class="n">inl</span> <span class="n">zeqz</span>

<span class="kn">theorem</span> <span class="n">t4</span><span class="o">:</span> <span class="mi">1</span><span class="bp">=</span><span class="mi">0</span> <span class="bp">∨</span> <span class="mi">1</span><span class="bp">=</span><span class="mi">1</span> <span class="o">:=</span>
             <span class="n">or</span><span class="bp">.</span><span class="n">inr</span> <span class="n">oeqo</span>
</pre></div>
</div>
<p>Once again, we emphasize that whether or not you’re using Lean or any
other tool or no tool at all, the strategy for proving a disjunction
is to prove at least one of its disjucts, and then to take that as
enough to prove the overall disjunction. You see that each form of
proposition has its own corresponding proof strategy (or at least one;
there might be several that work). In the cases we’ve seen so far, you
look at the constructor that was used to build the proposition and
from that you select the appropriate inference rule / strategy to use
to build the final proof. You then either have, or construct, the
proofs that you need to apply that rule to construct the required
proof.</p>
<p>As a computational object, a proof of a disjunction is like a
discriminated union in C or C++: an object containing one of two
values along with a label that tells you what kind of value it
contains. In this case, the label is given by the introduction rule
used to construct the proof object: either or.inl or or.inr.</p>
<div class="section" id="p-q-p-r-q-r-r-or-elimination">
<h3>[P / Q, P -&gt; R, Q -&gt; R] <a href="#id26"><span class="problematic" id="id27">|</span></a>- R  [Or Elimination]<a class="headerlink" href="#p-q-p-r-q-r-r-or-elimination" title="Permalink to this headline">¶</a></h3>
<p>Given a proof of P / Q, or elimination does not produce a proof of a
proposition involving either P or Q. Rather, it gives a proof of some
third proposition, R.  The justification is that we know that at least
one of P or Q is true; we also know that P is true, then R is implied,
and that if Q is true, then R is also implied; so it follows that R is
true in either case, at least one of which must hold, so it is true.</p>
</div>
</div>
<div class="section" id="working-with-generalized-propositions-in-lean">
<h2>Working with Generalized Propositions in Lean<a class="headerlink" href="#working-with-generalized-propositions-in-lean" title="Permalink to this headline">¶</a></h2>
<p>In Lean we can declare variables to be of given types without actually
defining values for them.  You can think of these as “assumptions that
we have values of certain types.” So for example, you can say, “assume
that P, Q, and R are arbitrary propositions (of type Prop)”.</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="kn">variables</span> <span class="n">P</span> <span class="n">Q</span> <span class="n">R</span><span class="o">:</span> <span class="kt">Prop</span>
</pre></div>
</div>
<p>If we wanted to, we could also assume that we have proofs of one or
more of these propositions by declaring variables to be of these
types.  Here’s one example (which we won’t use futher in this code).</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="kn">variable</span> <span class="n">proof_of_P</span><span class="o">:</span> <span class="n">P</span>
</pre></div>
</div>
<p>Now we can write somewhat more interesting propositions, and prove
them. Here’s an example in which we prove that if P ∧ Q is true then
we P is true. The proof is by the provisioning of a function that
given a proof of P ∧ Q returns a proof of P by applying and.elim_left
to its argument.</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="kn">theorem</span> <span class="n">t6</span><span class="o">:</span> <span class="n">P</span> <span class="bp">∧</span> <span class="n">Q</span> <span class="bp">→</span> <span class="n">P</span> <span class="o">:=</span>
<span class="bp">λ</span> <span class="n">PandQ</span><span class="o">:</span> <span class="n">P</span> <span class="bp">∧</span> <span class="n">Q</span><span class="o">,</span> <span class="n">and</span><span class="bp">.</span><span class="n">elim_left</span> <span class="n">PandQ</span>
</pre></div>
</div>
<ul class="simple">
<li></li>
</ul>
<p>Similarly we can prove that P ∧ Q → Q ∧ P</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="kn">theorem</span> <span class="n">t7</span><span class="o">:</span> <span class="n">P</span> <span class="bp">∧</span> <span class="n">Q</span> <span class="bp">→</span> <span class="n">Q</span> <span class="bp">∧</span> <span class="n">P</span> <span class="o">:=</span>
<span class="bp">λ</span> <span class="n">PandQ</span><span class="o">:</span> <span class="n">P</span> <span class="bp">∧</span> <span class="n">Q</span><span class="o">,</span>
<span class="n">and</span><span class="bp">.</span><span class="n">intro</span>
<span class="o">(</span><span class="n">and</span><span class="bp">.</span><span class="n">elim_right</span> <span class="n">PandQ</span><span class="o">)</span>
<span class="o">(</span><span class="n">and</span><span class="bp">.</span><span class="n">elim_left</span> <span class="n">PandQ</span><span class="o">)</span>
</pre></div>
</div>
</div>
<div class="section" id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">¶</a></h2>
<p>This unit has given an introduction to deductive logic using natural
deduction based on introduction and elimination rules that we first
saw in the unit on propositional logic. We saw that these rules are
semantically valid (based on truth tables), and now we take them as
valid ways of deducing the truth of propositions (conclusions) in
given contexts, in which we have proofs of sequences of propositions
(contexts, assumptions, premises).</p>
<p>As mathematicians and computer scientists, we’re often the goal of
proving some putative (unproven) theorem (aka conjecture). A key
question in such a case is what proof strategy to use to produce a
proof. The rules of natural deduction can help.  First, look at the
form of the proposition. Then ask what inference rule could be used to
deduce it. Then apply the strategy associated with that rule.</p>
<p>If you want to prove an equality, simplify and then apply the axiom
that says that identical terms can be considered equal without any
other proofs at all. If you want to prove a conjunction, obtain proofs
of the conjuncts, then deduce by “and introduction” the desired
result. If you want to prove an implication, P → Q, explain how the
assumption that you’re given a proof of P enables you to construct a
proof of Q (or if you’re using a tool like Lean, do this in a precise
way by writing a function).</p>
<p>Proof strategies emerge from the choices of inference rules needed to
produce a final result.  If you already have proofs of all premises
for a rule, just apply the rule. But in many cases, you don’t.</p>
<p>The twist is to read inference rules not from top to bottom: if I know
these things then I can conclude that. Instead, read them backwards:
from bottom to top: if I want to prove this, then it will suffice to
prove these other things, the premises, because if I have proofs of
those things, then I can apply this inference rule to get the final
proof that I want.</p>
<p>In this way, the problem of proving a complex conjecture is decomposed
into simpler problems, to prove each of the premises. You then apply
this idea recursively to each premise, selecting a proof strategy
appropriate for its form, and working backwards in this way until you
get to propositions for which proofs are available with no futher
recursion. An example is 0=0. We can get a proof of this using rfl
without any futher “backward chaining.” Once you’ve worked all the way
back to propositions for which you have “base case” proofs, you then
apply the inference rules going forward, to build the desired proof
from all of the elementary and intermediates proofs, until, voila, you
have what you need.</p>
<p>As an example, consider 1=1 ∧ 0=0. It’s a conjunction. A conjunction
can be proved using and.intro. It, however, requires proofs of the
conjuncts. So now we need proofs of 1=1 and of 0=0. Considering each
of these “sub-goals” recursively, we can obtains proofs without futher
recursion, using rfl. Given those proofs we can combine them going
forward using and.intro. And that’s how it works. Proving theorems in
this way is thus in effect an exercise in what amounts to “top-down
structured programming,” but what we’re building isn’t a program that
we intend to <em>run</em> but a proof that, if it type checks, witnesses the
truth of a proposition.</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="kn">theorem</span> <span class="n">t5</span><span class="o">:</span> <span class="mi">1</span><span class="bp">=</span><span class="mi">1</span> <span class="bp">∧</span> <span class="mi">0</span><span class="bp">=</span><span class="mi">0</span> <span class="o">:=</span> <span class="n">and</span><span class="bp">.</span><span class="n">intro</span> <span class="n">rfl</span> <span class="n">rfl</span>
</pre></div>
</div>
</div>
<div class="section" id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">¶</a></h2>
<p>(1) Write an implementation of comp (call it comp’), using a lambda
expression rather than the usual function definition notation.  This
problem gives practice writing function bodies as lambda expressions.</p>
<p>(2) Write three test cases for comp’ and generate proofs using the
strategy of “simplication and the reflexive property of equality.”</p>
<p>(3) Implement the Fibonacci function, fib, using the usual recursive
definition. Test it for n = 0, n = 1, and n = 10, by writing and
proving theorems about what it computes (or should compute) in these
cases. Hint: Write your cases in the definition of the function for 0,
1, and n+2 (covering the cases from 2 up). Here you get practice
writing recursive functions in Lean. The syntax is similar to that of
the Haskell language.</p>
<p>(4) Uncomment then complete this proof of the proposition, “Hello
World” = “Hello” + ” World” (which we write using the string.append
function).  Put your anwer in place of the &lt;answer&gt; string.  This
example introduces Lean’s string type, which you might want to use at
some point. It also gives you an example showing that rfl works for
diverse types. It’s polymorphic, as we said.</p>
<div class="highlight-lean"><div class="highlight"><pre><span></span><span class="c1">--theorem hw : &quot;Hello World&quot; = string.append &quot;Hello&quot; &quot; World&quot; := &lt;answer&gt;</span>
</pre></div>
</div>
<p>(5) Prove P ∧ Q ∧ R → R . Hint: ∧ is right-associative.  In other
words, P ∧ Q ∧ R means P ∧ (Q ∧ R). A proof of this proposition will
thus have a pair inside a pair.</p>
<p>(6) Prove P → Q → (P ∧ Q). You can read this as saying that if you
have a proof of P, then if you (also) have a proof of Q ,then you can
produce a proof of P and Q.  Hint: → is right associative, so P → Q →
(P ∧ Q) means P → (Q → (P ∧ Q)). A proof will be a function that takes
a proof of P and returns … you guessed it, a function that takes a
proof of Q and that returns a proof of P ∧ Q. The body of the outer
lambda will thus use a lambda.</p>
<div class="section" id="extra-kudos-problem">
<h3>Extra Kudos Problem<a class="headerlink" href="#extra-kudos-problem" title="Permalink to this headline">¶</a></h3>
<p>Prove (P ∨ Q) → (P → R) → (Q → R) -&gt; R. This looks scary, but think
about it in the context of material you’ve already learned about. It
say that if you have a proof of (P ∨ Q), then if you also have a proof
of (P → R), then if you also have a proof of (Q → R), then you can
derivea proof of R. The “or elimination” rule looked like this. You’ll
want to use that rule as part of your answer. However, the form of the
proposition to be proved here is an implication, so a proof will have
to be in the form of be a function. It will take the disjunction as an
argument. Then just apply the or elimination rule in Lean, which is
written as or.elim.</p>
<p>For fun and insight, check the type of orelim, the proposition we just
proved. Notice how P, Q, and R are generalized to be <em>any</em>
propositions at all.</p>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="nav-item nav-item-0"><a href="index.html">Discrete Mathematics for Software Professionals 1 documentation</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright .
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.6.5.
    </div>
  </body>
</html>